# coding: utf-8

import pandas as pd
from string import Template

# This script generates ODB schema code for direct inclusion into the ASKAP Sky Model Service code.
# It also generates the Ice DTO objects from the same definitions.

# Define the Outputs
# Each schema file defines a dictionary with the following keys:
# * **input**: the input spreadsheet
# * **output**: the output file
# * **parse_cols**: zero-based column indicies for parsing from the spreadsheet
# * **skiprows**: zero-based row indicies that should be skipped in the spreadsheet

# The mapping from database types to C++ types
TYPE_MAP = {
    'BIGINT': 'boost::int64_t',
    'REAL': 'float',
    'DOUBLE': 'double',
    'VARCHAR': 'std::string',
    'TEXT': 'std::string',
    'BOOLEAN': 'bool',
    'INTEGER': 'boost::int32_t',
    'DATETIME': 'boost::posix_time::ptime',
}

# The mapping from database types to Slice types
SLICE_TYPE_MAP = {
    'BIGINT': 'long',
    'REAL': 'float',
    'DOUBLE': 'double',
    'VARCHAR': 'string',
    'TEXT': 'string',
    'BOOLEAN': 'bool',
    'INTEGER': 'int',
    'DATETIME': 'string',  # will need to convert to a canonical string representation
}

COMMON_FILE_HEADER = '''\
/// ----------------------------------------------------------------------------
/// This file is generated by schema_definitions/generate.py.
/// Do not edit directly or your changes will be lost!
/// ----------------------------------------------------------------------------
///
/// @copyright (c) 2016 CSIRO
/// Australia Telescope National Facility (ATNF)
/// Commonwealth Scientific and Industrial Research Organisation (CSIRO)
/// PO Box 76, Epping NSW 1710, Australia
/// atnf-enquiries@csiro.au
///
/// This file is part of the ASKAP software distribution.
///
/// The ASKAP software distribution is free software: you can redistribute it
/// and/or modify it under the terms of the GNU General Public License as
/// published by the Free Software Foundation; either version 2 of the License,
/// or (at your option) any later version.
///
/// This program is distributed in the hope that it will be useful,
/// but WITHOUT ANY WARRANTY; without even the implied warranty of
/// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
/// GNU General Public License for more details.
///
/// You should have received a copy of the GNU General Public License
/// along with this program; if not, write to the Free Software
/// Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
///
/// @author Daniel Collins <daniel.collins@csiro.au>
'''

COMMON_SLICE_HEADER = COMMON_FILE_HEADER + '''
#pragma once

#include <CommonTypes.ice>
'''

SLICE_NAMESPACES = '''
module askap
{
module interfaces
{
module skymodelservice
{
'''

CONTINUUM_COMPONENT_HEADER = '''

    /**
     * A continuum component.
     **/
    class ContinuumComponent
    {
        optional(1) ContinuumComponentPolarisation polarisation;

'''

POLARISATION_HEADER = COMMON_SLICE_HEADER + SLICE_NAMESPACES + \
'''
    /**
     * Continuum component polarisation data.
     **/
    struct ContinuumComponentPolarisation
    {
'''

SLICE_FOOTER = '''\
    };

};
};
};
'''

CONTINUUM_COMPONENT_SPEC = './GSM_casda.continuum_component_description.xlsx'
POLARISATION_SPEC = './GSM_casda_polarisation.xlsx'

FILES = [
    {
        'input': CONTINUUM_COMPONENT_SPEC,
        'output': '../schema/ContinuumComponent.i',
        'parse_cols': None,
        'skiprows': [0],
    },
    {
        'input': POLARISATION_SPEC,
        'output': '../schema/Polarisation.i',
        'parse_cols': None,
        'skiprows': [0],
    },
    {
        'input': './GSM_data_source_description.xlsx',
        'output': '../schema/DataSource.i',
        'parse_cols': None,
        'skiprows': [0],
    },
]

# configuration for Slice file generation.
# This is setup to write to the same file, with continuum component appending to
# the polarisation file (thus the difference between headers and footers)
# It also means that order is important, polarisation must come before component
# definition
SLICE_FILES = [
    {
        'input': POLARISATION_SPEC,
        'output': '../SkyModelServiceDTO.ice',
        'parse_cols': None,
        'skiprows': [0],
        'file_header': POLARISATION_HEADER,
        'file_footer': '    };',
        'append_to_file': False,
    },
    {
        'input': CONTINUUM_COMPONENT_SPEC,
        'output': '../SkyModelServiceDTO.ice',
        'parse_cols': None,
        'skiprows': [0],
        'file_header': CONTINUUM_COMPONENT_HEADER,
        'file_footer': SLICE_FOOTER,
        'append_to_file': True,
    },
]

def load(
    filename,
    sheetname='Catalogue description',
    parse_cols=None,
    skiprows=None,
    converters={
            'name': str,
            'description': str,
            'datatype': str,
            'ucd': str,
            'units': str,
            'notes': str,
            'include_in_gsm': bool,
            'index': bool,
            'nullable': bool,
            'lsm_view': bool,
            }):
    """Load the table data from a CASDA definition spreadsheet"""
    data = pd.read_excel(
        filename,
        sheetname=sheetname,
        converters=converters,
        parse_cols=parse_cols,
        skiprows=skiprows)

    # Drop any rows with missing data in the name or datatype columns
    data.dropna(subset=['name', 'datatype'], inplace=True)

    # fill any remaining missing data with empty strings
    data.fillna('', inplace=True)

    return data[data.include_in_gsm == True]


def to_camel_case(snake_str):
    '''Converts a snake string to lower camel case.
    E.G.: my_identifier --> myIdentifier
    '''
    components = snake_str.split('_')
    # We capitalize the first letter of each component except the first one
    # with the 'title' method and join them together.
    return components[0] + "".join(x.title() for x in components[1:])


class Field(object):
    "Represents a database field"
    def __init__(self, df_row, is_view, type_map, indent=0, camel_case=False):
        self.name = df_row.name.strip()
        if camel_case:
            self.name = to_camel_case(self.name)

        self.comment = df_row.description.strip()
        self.raw_type = df_row.datatype.strip()
        self.dtype = type_map[self.raw_type]
        self.units = df_row.units.strip()
        self.indexed = df_row.index
        self.nullable = df_row.nullable
        self.is_view = is_view
        self.lsm_view = df_row.lsm_view
        self._magic_names = {}
        self._indent = indent

        # not every tablespec contains the ucd column
        try:
            self.ucd = df_row.ucd.strip()
        except:
            self.ucd = ''

    def __repr__(self):
        return self.__str__()

    def __str__(self):
        _str = self._comment()

        if not self.is_view:
            # handle any pragmas for magic field names
            if self.name in self._magic_names:
                for pragma in self._magic_names[self.name]:
                    _str.append(pragma)

            if self.indexed:
                _str.append('#pragma db index')

            if self.nullable:
                _str.append('#pragma db null')
            else:
                _str.append('#pragma db not_null')

        # the field definition
        _str.append('{0} {1};'.format(
            self.dtype,
            self.name))

        # indentation
        _str = [self._indent * ' ' + line for line in _str]

        _str.append('\n')

        return '\n'.join(_str)

    def _comment(self):
        "Builds the comment text"
        comments = []
        if self.units:
            comments.append('@brief {0} ({1})'.format(self.comment, self.units))
        else:
            comments.append('@brief {0}'.format(self.comment))
        comments.append('UCD: {0}'.format(self.ucd))
        return ['/// ' + c for c in comments]


def get_fields(data_frame, type_map, is_view, indent=0, camel_case=False):
    "Unpacks a tablespec data frame into a list of field objects"
    fields = []
    for row in data_frame.itertuples(index=False):
        # print(row)
        field = Field(row, is_view, type_map, indent=indent, camel_case=camel_case)
        fields.append(field)
    return fields


def write_output(
    data_frame,
    filename,
    type_map,
    is_view=False,
    indent=0,
    camel_case=False,
    append_to_file=False,
    file_header=None,
    file_footer=None):
    "Writes the data model fields to a file"
    mode = 'a' if append_to_file else 'w'
    with open(filename, mode) as out:
        if file_header:
            out.write(file_header)
        for field in get_fields(data_frame, type_map, is_view, indent=indent, camel_case=camel_case):
            if not is_view or (is_view and field.lsm_view):
                out.write(str(field))
        if file_footer:
            out.write(file_footer)

#--------------------------------------------------
# VOTable Parser function code generation section
#--------------------------------------------------
VOTABLE_PARSER_HEADER = COMMON_FILE_HEADER + '''
#pragma once

// System includes
#include <string>
#include <boost/cstdint.hpp>
#include <boost/noncopyable.hpp>
#include <boost/shared_ptr.hpp>
#include <boost/variant.hpp>

// ASKAPsoft includes
#include <votable/VOTable.h>

// Local package includes
#include "datamodel/ContinuumComponent.h"
#include "SmsTypes.h"

namespace askap {
namespace cp {
namespace sms {

'''

HEADER_POSTAMBLE = '''

}
}
}
'''

PARSE_POLARISATION_ROW_FIELD_START = '''
void parsePolarisationRowField(
    const std::string& ucd,
    const std::string& name,
    const std::string& type,
    const std::string& unit,
    const std::string& value,
    boost::shared_ptr<datamodel::Polarisation> pPol) {

    ASKAPASSERT(pPol.get());
'''

PARSE_COMPONENT_ROW_FIELD_START = '''
void parseComponentRowField(
    size_t row_index,
    const std::string& ucd,
    const std::string& name,
    const std::string& type,
    const std::string& unit,
    const std::string& value,
    std::vector<datamodel::ContinuumComponent>& components,
    std::vector<Coordinate>& coord_buffer) {

    ASKAPASSERT(row_index >= 0);
    ASKAPASSERT(row_index < components.size());
    ASKAPASSERT(row_index < coord_buffer.size());
'''

COMPONENT_UCD_FIELD_PARSE_PATTERN = '''
    if (boost::iequals(ucd, "$ucd")) {
        ASKAPASSERT($unitCheckExpression);
        ASKAPASSERT(boost::iequals(type, "$votype"));
        components[row_index].$fieldname = boost::lexical_cast<$cpptype>(value);
'''

COMPONENT_NO_UCD_FIELD_PARSE_PATTERN = '''
    if (boost::iequals(name, "$fieldname")) {
        // Some fields do not have a unique UCD. They are matched by name.
        ASKAPASSERT($unitCheckExpression);
        ASKAPASSERT(boost::iequals(type, "$votype"));
        components[row_index].$fieldname = boost::lexical_cast<$cpptype>(value);
    }'''

POLARISATION_UCD_FIELD_PARSE_PATTERN = '''
    if (boost::iequals(ucd, "$ucd")) {
        ASKAPASSERT($unitCheckExpression);
        ASKAPASSERT(boost::iequals(type, "$votype"));
        pPol->$fieldname = boost::lexical_cast<$cpptype>(value);
'''

POLARISATION_NO_UCD_FIELD_PARSE_PATTERN = '''
    if (boost::iequals(name, "$fieldname")) {
        // Some fields do not have a unique UCD. They are matched by name.
        ASKAPASSERT($unitCheckExpression);
        ASKAPASSERT(boost::iequals(type, "$votype"));
        pPol->$fieldname = boost::lexical_cast<$cpptype>(value);
    }'''

def write_field_parsing_code(
    out,
    fields,
    db_to_votable_type_map,
    ucd_skip_list,
    ucd_field_template,
    no_ucd_field_template,
    special_case_ra_dec=False):
    count = 0
    for field in fields:
        if field.units:
            unit_check = 'boost::iequals(unit, "{0}")'.format(field.units)
        else:
            unit_check = 'unit.empty() || unit == "--" || unit == "none"'

        if field.ucd not in ucd_skip_list:
            statement = Template(ucd_field_template).substitute(
                    ucd=field.ucd,
                    unitCheckExpression=unit_check,
                    votype=db_to_votable_type_map[field.raw_type],
                    fieldname=field.name,
                    cpptype=field.dtype)
            if count:
                out.write('\n    else ')
            out.write(statement)

            # special case for RA and declination
            if special_case_ra_dec:
                if field.ucd.casefold() == 'pos.eq.ra;meta.main'.casefold():
                    out.write(
                        Template('        coord_buffer[row_index].ra = components[row_index].$fieldname;\n').substitute(
                            fieldname=field.name))
                elif field.ucd.casefold() == 'pos.eq.dec;meta.main'.casefold():
                    out.write(
                        Template('        coord_buffer[row_index].dec = components[row_index].$fieldname;\n').substitute(
                            fieldname=field.name))

            out.write('    }')
            count += 1
        elif field.ucd == 'meta.code':
            statement = Template(no_ucd_field_template).substitute(
                    unitCheckExpression=unit_check,
                    votype=db_to_votable_type_map[field.raw_type],
                    fieldname=field.name,
                    cpptype=field.dtype)
            if count:
                out.write('\n    else ')
            out.write(statement)
            count += 1

def write_votable_parser():
    "Writes the VOTable to data model class parsing code"
    print('\t../service/VOTableParser.h')
    with open('../service/VOTableParser.h', 'w') as out:
        out.write(VOTABLE_PARSER_HEADER)

        # map the types in the spec spreadsheet to the strings expected in the
        # VOTable XML file
        db_to_votable_type_map = {
            'BIGINT': 'int',
            'BIGINT UNSIGNED': 'int',
            'REAL': 'float',
            'DOUBLE': 'double',
            'VARCHAR': 'char',
            'TEXT': 'char',
            'BOOLEAN': 'int',
            'INTEGER': 'int',
            'INTEGER UNSIGNED': 'int',
            'DATETIME': 'char',
        }

        out.write(PARSE_COMPONENT_ROW_FIELD_START)
        write_field_parsing_code(
            out,
            get_fields(load(CONTINUUM_COMPONENT_SPEC, skiprows=[0]), TYPE_MAP, False),
            db_to_votable_type_map,
            ['', 'meta.code'],
            COMPONENT_UCD_FIELD_PARSE_PATTERN,
            COMPONENT_NO_UCD_FIELD_PARSE_PATTERN,
            special_case_ra_dec=True)
        out.write('\n}\n\n')

        # Write the polarisation parser function
        out.write(PARSE_POLARISATION_ROW_FIELD_START)
        write_field_parsing_code(
            out,
            get_fields(load(POLARISATION_SPEC, skiprows=[0]), TYPE_MAP, False),
            db_to_votable_type_map,
            ['', 'meta.code'],
            POLARISATION_UCD_FIELD_PARSE_PATTERN,
            POLARISATION_NO_UCD_FIELD_PARSE_PATTERN,
            special_case_ra_dec=False)
        out.write('\n}')
        out.write(HEADER_POSTAMBLE)

#--------------------------------------------------
# Data marshalling code generation section
# The data marshaller transfers data from the ORM objects retrieved from
# a database query into the Ice DTO structures.
#
# Only database fields that have the lsm_view flag set to true are marshalled.
#--------------------------------------------------
DATA_MARSHALLER_HEADER = COMMON_FILE_HEADER + '''
#pragma once

// System includes
#include <string>
#include <vector>
#include <boost/cstdint.hpp>
#include <boost/shared_ptr.hpp>

// ASKAPsoft includes
#include <askap/AskapError.h>
#include <askap/AskapLogging.h>

// Ice interfaces
#include <SkyModelService.h>
#include <SkyModelServiceDTO.h>

// Local package includes
#include "datamodel/ContinuumComponent.h"
#include "SmsTypes.h"

namespace askap {
namespace cp {
namespace sms {


/// @brief Transfers data from the datamodel::ContinuumComponent class to the
/// Ice DTO class. If present, polarisation data will be added to the optional
/// polarisation member of ContinuumComponent.
///
/// @param[in] components Pointer to a vector of components for transfer.
/// @throw AskapError Thrown if there are errors.
/// @return askap::interfaces::skymodelservice::ComponentSeq
askap::interfaces::skymodelservice::ComponentSeq marshallComponentsToDTO(
    boost::shared_ptr< std::vector<datamodel::ContinuumComponent> > components)
{
    return askap::interfaces::skymodelservice::ComponentSeq();
}
'''

def write_orm_to_dto_marshaller():
    '''Generates a function for marshalling data from the ORM classes into
    the Ice DTO structures.'''
    print('\t../service/DataMarshalling.h')
    with open('../service/DataMarshalling.h', 'w') as out:
        out.write(DATA_MARSHALLER_HEADER)
        out.write(HEADER_POSTAMBLE)


if __name__ == '__main__':
    print('Generating tables ...')
    for f in FILES:
        print('\t' + f['output'])
        data = load(
            f['input'],
            parse_cols=f['parse_cols'],
            skiprows=f['skiprows'])
        write_output(data, f['output'], TYPE_MAP)

    print('Generating slice data transfer objects (DTO) ...')
    for f in SLICE_FILES:
        print('\t' + f['output'])
        data = load(
            f['input'],
            parse_cols=f['parse_cols'],
            skiprows=f['skiprows'])

        write_output(
            data,
            f['output'],
            SLICE_TYPE_MAP,
            is_view=True,
            indent=8,
            camel_case=True,
            append_to_file=f['append_to_file'],
            file_header=f['file_header'],
            file_footer=f['file_footer'])

    print('Generating VOTable to datamodel parsing code ...')
    write_votable_parser()

    print('Generating data marshalling function ...')
    write_orm_to_dto_marshaller()

    print('Done')
    print("* Don't forget to move the generated Ice files to Code/Interfaces/slice/current with 'make generate_ice'")
