# coding: utf-8

import pandas as pd

# This notebook generates ODB schema code for direct inclusion into the ASKAP Sky Model Service code.

# Define the Outputs
# Each schema file defines a dictionary with the following keys:
# * **input**: the input spreadsheet
# * **output**: the output file
# * **parse_cols**: zero-based column indicies for parsing from the spreadsheet
# * **skiprows**: zero-based row indicies that should be skipped in the spreadsheet

files = [
    {
        'input': './GSM_casda.continuum_component_description.xlsx',
        'output': '../schema/ContinuumComponent.i',
        'parse_cols': None,
        'skiprows': [0],
    },
    {
        'input': './GSM_casda_polarisation.xlsx',
        'output': '../schema/Polarisation.i',
        'parse_cols': None,
        'skiprows': [0],
    },
    {
        'input': './GSM_data_source_description.xlsx',
        'output': '../schema/DataSource.i',
        'parse_cols': None,
        'skiprows': [0],
    },
]

view_files = [
    {
        'inputs': [
            './GSM_casda.continuum_component_description.xlsx',
            './GSM_casda_polarisation.xlsx',
            ],
        'output': '../schema/ContinuumComponentLsmView.i',
        'parse_cols': None,
        'skiprows': [0],
    },
]

def load(
    filename,
    sheetname='Catalogue description',
    parse_cols=None,
    skiprows=None,
    converters={
            'name': str,
            'description': str,
            'datatype': str,
            'units': str,
            'notes': str,
            'include_in_gsm': bool,
            'index': bool,
            'nullable': bool,
            'lsm_view': bool,
            }):
    """Load the table data from a CASDA definition spreadsheet"""
    data = pd.read_excel(
        filename,
        sheetname=sheetname,
        converters=converters,
        parse_cols=parse_cols,
        skiprows=skiprows)

    # Drop any rows with missing data in the name or datatype columns
    data.dropna(subset=['name', 'datatype'], inplace=True)

    # fill any remaining missing data with empty strings
    data.fillna('', inplace=True)

    return data[data.include_in_gsm == True]

type_map = {
    'BIGINT': 'boost::int64_t',
    'BIGINT UNSIGNED': 'boost::uint64_t',
    'REAL': 'float',
    'DOUBLE': 'double',
    'VARCHAR': 'std::string',
    'TEXT': 'std::string',
    'BOOLEAN': 'bool',
    'INTEGER': 'boost::int32_t',
    'INTEGER UNSIGNED': 'boost::uint32_t',
    'DATETIME': 'boost::posix_time::ptime',
}

class Field(object):
    "Represents a database field"
    def __init__(self, df_row, is_view):
        self.name = df_row.name.strip()
        self.comment = df_row.description.strip()
        self.dtype = type_map[df_row.datatype.strip()]
        self.units = df_row.units.strip()
        self.indexed = df_row.index
        self.nullable = df_row.nullable
        self.is_view = is_view
        self._magic_names = {}

    def __repr__(self):
        return self.__str__()

    def __str__(self):
        _str = self._comment()

        if not self.is_view:
            # handle any pragmas for magic field names
            if self.name in self._magic_names:
                for pragma in self._magic_names[self.name]:
                    _str.append(pragma)

            if self.indexed:
                _str.append('#pragma db index')

            if self.nullable:
                _str.append('#pragma db null')
            else:
                _str.append('#pragma db not_null')

        # the field definition
        _str.append('{0} {1};'.format(
            self.dtype,
            self.name))

        # indentation
        # indent = 4
        # _str = [indent * ' ' + line for line in _str]

        _str.append('\n')

        return '\n'.join(_str)

    def _comment(self):
        "Builds the comment text"
        comments = []
        if self.units:
            comments.append('@brief {0} ({1})'.format(self.comment, self.units))
        else:
            comments.append('@brief {0}'.format(self.comment))
        return ['/// ' + c for c in comments]


def get_fields(data_frame, is_view=False):
    "Unpacks a tablespec data frame into a list of field objects"
    fields = []
    for row in data_frame.itertuples(index=False):
        # print(row)
        field = Field(row, is_view)
        fields.append(field)

    return fields


def write_output(data_frame, filename, is_view=False):
    "Writes the data model fields to an include file"
    with open(filename, 'w') as out:
        for field in get_fields(data_frame, is_view):
            out.write(str(field))

HEADER_PREAMBLE = '''/// ----------------------------------------------------------------------------
/// This file is generated by schema_definitions/generate.py.
/// Do not edit directly or your changes will be lost!
/// ----------------------------------------------------------------------------
///
/// @file VOTableParser.h
///
/// @copyright (c) 2016 CSIRO
/// Australia Telescope National Facility (ATNF)
/// Commonwealth Scientific and Industrial Research Organisation (CSIRO)
/// PO Box 76, Epping NSW 1710, Australia
/// atnf-enquiries@csiro.au
///
/// This file is part of the ASKAP software distribution.
///
/// The ASKAP software distribution is free software: you can redistribute it
/// and/or modify it under the terms of the GNU General Public License as
/// published by the Free Software Foundation; either version 2 of the License,
/// or (at your option) any later version.
///
/// This program is distributed in the hope that it will be useful,
/// but WITHOUT ANY WARRANTY; without even the implied warranty of
/// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
/// GNU General Public License for more details.
///
/// You should have received a copy of the GNU General Public License
/// along with this program; if not, write to the Free Software
/// Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
///
/// @author Daniel Collins <daniel.collins@csiro.au>

#ifndef ASKAP_CP_SMS_VOTABLEPARSER_H
#define ASKAP_CP_SMS_VOTABLEPARSER_H

// System includes
#include <string>
#include <boost/noncopyable.hpp>
#include <boost/shared_ptr.hpp>
#include <boost/variant.hpp>

// ASKAPsoft includes
#include <votable/VOTable.h>


// Local package includes
#include "datamodel/ContinuumComponent.h"

namespace askap {
namespace cp {
namespace sms {

'''

HEADER_POSTAMBLE = '''

}
}
}

#endif
'''

VO_2_CPP_TYPE_COERCE_PATTERN = '''if (boost::iequals(type, "%s")) {
        v = boost::lexical_cast<%s>(value);
    }'''

def write_votable_parser():
    "Writes the VOTable to data model class parsing code"
    with open('../service/VOTableParser.h', 'w') as out:
        out.write(HEADER_PREAMBLE)

        # string to C++ type coercion
        votable_to_cpp_type_map = {
            'float': 'float',
            'double': 'double',
            'boolean': 'bool',
            'int': 'boost::int32_t',
            'char': 'std::string',
        }
        variant_typedef = 'typedef boost::variant<{0}> VOTableValue;'.format(
            ', '.join(votable_to_cpp_type_map.values()))
        out.write(variant_typedef)
        out.write('\n\nValueTypes VOTableData::coerce_value(const std::string& value, const std::string& type) {')
        out.write('\n\tValueTypes v;\n')
        i = 0
        for k, v in votable_to_cpp_type_map.items():
            out.write(
                '\n    ' +
                ('' if i < 1 else 'else ') +
                VO_2_CPP_TYPE_COERCE_PATTERN % (k, v))
            i += 1

        out.write('\n\n    return v;')
        out.write('\n}')

        # The main parsing function

        out.write(HEADER_POSTAMBLE)


if __name__ == '__main__':
    print('Generating tables ...')
    for f in files:
        print('\t' + f['output'])
        data = load(
            f['input'],
            parse_cols=f['parse_cols'],
            skiprows=f['skiprows'])
        write_output(data, f['output'])

    print('Generating views ...')
    for f in view_files:
        print('\t' + f['output'])
        # Load all the input data frames that will be combined into the view
        view_data = [
            load(i, parse_cols=f['parse_cols'], skiprows=f['skiprows'])
            for i in f['inputs']]

        # concatenate the dataframes, and then select just the fields that have
        # the view flag set
        data = pd.concat(view_data).query('lsm_view == True')
        write_output(data, f['output'], is_view=True)

    print('Generating VOTable to datamodel parsing code ...')
    write_votable_parser()

    print('Done')
